// Import required dependencies from the Raindrop framework
// The Service class provides the base functionality for our worker
import { services } from '@liquidmetal-ai/raindrop-framework';
// Import environment variable types generated by Raindrop
import { Env } from './raindrop.gen';

// Define the structure for responses returned by tools
// Each tool response includes:
// - success: Whether the tool executed successfully
// - data: The actual data returned by the tool (typed as any)
// - error: Optional error message if the tool failed
interface ToolResponse {
  success: boolean;
  data: any;
  error?: string;
}

/**
 * Agent class that implements a single-loop reasoning and action model.
 * The agent follows this process:
 * 1. Receives user input
 * 2. Uses Groq LLM API to reason about what action to take
 * 3. Either uses a tool to gather information or provides final answer
 * 4. Repeats steps 2-3 until it has enough information to answer or hits max depth
 */
class Agent {
  // Store the full conversation history as an array of strings
  private context: string[] = [];
  // Store environment variables needed for API keys etc
  private env: Env;

  constructor(env: Env) {
    this.env = env;
  }

  /**
   * Main processing function that handles user input and generates responses.
   * This implements the core reasoning loop:
   * 1. Add user input to conversation history
   * 2. Ask Groq LLM to reason about what's needed
   * 3. Either use a tool (weather, news) or provide final answer
   * 4. Repeat until we have an answer or hit max iterations
   * 
   * @param userInput - The text input from the user
   * @param maxDepth - Maximum number of reasoning iterations (default 10)
   * @returns A string containing the agent's final response
   */
  async processInput(userInput: string, maxDepth: number = 10): Promise<string> {
    // Add user input to conversation history
    this.context.push(`User: ${userInput}`);
    console.log("in processInput");

    // Track whether we've reached a final answer
    let isComplete = false;
    let finalAnswer = '';
    let currentDepth = 0;

    // Main reasoning loop - continue until we have an answer or hit max depth
    while (!isComplete && currentDepth < maxDepth) {
      console.log(`Processing iteration ${currentDepth} of ${maxDepth}`);

      // Call Groq API to get the next reasoning step
      // We use their llama-3.1-70b model which is optimized for reasoning
      const reasoningResponse = await fetch('https://api.groq.com/openai/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.env.GROQ_API_KEY}`
        },
        body: JSON.stringify({
          model: 'llama-3.1-70b-versatile',
          messages: [{
            role: 'system',
            content: `You are an AI assistant that always responds in JSON format. You have access to these tools:
- weather: Get the current weather for a location. Requires arguments in format: 
  {
    "city": string (required), 
    "country": string (optional, two-letter country code),
    "state": string (optional, state code for US locations)
  }
  Example: { "city": "London" } or { "city": "New York", "state": "NY", "country": "US" }
- news: Retrieve news articles based on a search query. Requires arguments in format:
  {
    "query": string (required),
    "fromDate": string (optional, in YYYY-MM-DD format)
  }
  Example: { "query": "technology", "fromDate": "2023-10-01" }
  Set date to one week ago (${new Date(Date.now() - 7 * 24 * 60 * 60 * 1000).toISOString().split('T')[0]}) if no date is provided
- short_term_memory: Access to current conversation context
- long_term_memory: Access to past conversations

For each user request, analyze:
1. What information is needed to answer?
2. What tools (if any) should be used?
3. Is enough information available to answer?

IMPORTANT: After using a tool, evaluate the information received. If you have enough information, provide a final answer. If not, consider using a different tool. Do not use the same tool repeatedly with the same arguments.

Your response must follow this exact JSON schema:
{
  "thought": "string (your reasoning about what's needed)",
  "action": "string (either 'use_tool' or 'provide_answer')",
  "tool": "string (tool name if action is use_tool, null otherwise)", 
  "arguments": object | null (see tool descriptions for required formats),
  "answer": "string (final answer if action is provide_answer, null otherwise). In your answer, include code in a code block if any was generated"
}`
          }, {
            role: 'user',
            content: `Current context:\n${this.context.join('\n')}\n\nWhat should be done next?`
          }],
          temperature: 0.7,
          response_format: { type: "json_object" }  // Force JSON output
        })
      });

      // Get response as text for logging/debugging
      const responseBody = await reasoningResponse.text();
      console.log('API Response:', responseBody);

      try {
        // Parse the nested JSON responses
        const reasoningData = JSON.parse(responseBody);
        const reasoning = JSON.parse(reasoningData.choices[0].message.content);

        // Handle the AI's decision - either provide final answer or use a tool
        if (reasoning.action === 'provide_answer') {
          // We have enough information - store the answer and complete
          finalAnswer = reasoning.answer;
          isComplete = true;
        } else if (reasoning.action === 'use_tool') {
          // We need more information - call the appropriate tool
          const toolResult = await this.useTool(reasoning.tool, reasoning.arguments);

          // If the tool returned useful information, add it to context
          if (toolResult.success && toolResult.data.content) {
            this.context.push(`Tool Result (${reasoning.tool}): 
Information received:
${JSON.stringify(toolResult.data.content, null, 2)}

What would you like to do with this information?`);
          } else {
            // Tool failed - log error and add failure note to context
            console.error('Tool did not return useful information:', toolResult.error);
            this.context.push(`Tool (${reasoning.tool}) failed to provide useful information.`);
          }
        }
      } catch (error) {
        // Handle any JSON parsing errors
        console.error('JSON Parsing Error:', error);
        throw error;
      }

      currentDepth++;
    }

    // If we hit max depth without completing, return an error message
    if (!isComplete) {
      finalAnswer = `I apologize, but I was unable to reach a conclusion within the maximum allowed ${maxDepth} reasoning steps.`;
    }

    // Add the final answer to context and return it
    this.context.push(`Assistant: ${finalAnswer}`);
    return finalAnswer;
  }

  /**
   * Tool handling function that provides access to different capabilities.
   * Available tools:
   * - weather: Get current weather for a location using OpenWeatherMap API
   * - news: Get news articles based on search query using NewsAPI
   * - short_term_memory: Access current conversation context
   * - long_term_memory: Access historical conversations (currently mocked)
   * 
   * @param tool - Name of the tool to use
   * @param args - Arguments to pass to the tool
   * @returns ToolResponse containing success/failure and any returned data
   */
  private async useTool(tool: string, args: any): Promise<ToolResponse> {
    switch (tool) {

      // Get news articles based on a search query
      case 'news':
        console.log("in news tool");
        const { query, fromDate } = args;

        try {
          const newsResponse = await fetch(
            `https://newsapi.org/v2/everything?` +
            `q=${encodeURIComponent(query)}` +
            `${fromDate ? `&from=${fromDate}` : ''}` +
            `&sortBy=popularity` +
            `&apiKey=${this.env.NEWS_API_KEY}`,
            {
              headers: {
                'User-Agent': 'LiquidMetal AI Agent/1.0',
                'Content-Type': 'application/json'
              }
            }
          );

          if (!newsResponse.ok) {
            console.error('News API error:', await newsResponse.text());
            return {
              success: false,
              data: null,
              error: `Failed to fetch news: ${newsResponse.status} ${newsResponse.statusText}`
            };
          }

          const newsData = await newsResponse.json();

          // Check if we got any articles
          if (!newsData.articles || newsData.articles.length === 0) {
            return {
              success: false,
              data: null,
              error: 'No news articles found'
            };
          }

          return {
            success: true,
            data: {
              type: 'news',
              content: {
                articles: newsData.articles.slice(0, 5) // Only return top 5 articles
              }
            }
          };
        } catch (error) {
          console.error('News API error:', error);
          return {
            success: false,
            data: null,
            error: `Failed to fetch news: ${error.message}`
          };
        }

      // Get the current weather in a given city using OpenWeatherMap API
      case 'weather':
        console.log("in weather tool");
        const { city, country = '', state = '' } = args;
        const location = [city, state, country].filter(Boolean).join(',');

        const weatherResponse = await fetch(
          `https://api.openweathermap.org/data/2.5/weather?q=${location}&appid=${this.env.WEATHER_API_KEY}`
        );

        if (!weatherResponse.ok) {
          return {
            success: false,
            data: null,
            error: 'Location not found'
          };
        }

        const weatherData = await weatherResponse.json();
        return {
          success: true,
          data: {
            type: 'weather',
            content: weatherData
          }
        };

      // Access the current conversation history stored in context
      case 'short_term_memory':
        console.log("in short term memory tool");
        return {
          success: true,
          data: { type: 'conversation', content: this.context }
        };

      // Access past conversations (currently returns mock data)
      case 'long_term_memory':
        console.log("in long term memory tool");
        return {
          success: true,
          data: { type: 'past_conversations', content: 'There are no long term memories yet' }
        };

      // Handle unknown tool requests
      default:
        return {
          success: false,
          data: null,
          error: 'Unknown tool'
        };
    }
  }
}


/**
 * Main service class that handles HTTP requests and manages the Agent instance.
 * This class:
 * 1. Initializes the agent with environment variables
 * 2. Handles incoming POST requests with JSON body containing 'input' field
 * 3. Validates environment variables and request format
 * 4. Returns JSON responses with agent output or error messages
 */
export default class extends services.Service<Env> {
  // Instance of our AI agent
  private agent: Agent;

  constructor(context: ExecutionContext, env: Env) {
    super(context, env);
    this.env = env;
    this.agent = new Agent(env);
  }

  /**
   * Handles incoming HTTP requests to process user inputs through the agent.
   * Expects POST requests with a JSON body containing an 'input' field.
   * Validates environment variables and request format.
   * Returns JSON response with agent's output or error message.
   * 
   * @param request - The incoming HTTP request
   * @returns Response with the agent's processed output or error message
   */
  async fetch(request: Request): Promise<Response> {
    try {
      // First verify all required environment variables are present
      if (!this.env || !this.env.GROQ_API_KEY) {
        console.error('Environment not properly configured:', {
          hasEnv: Boolean(this.env),
          envKeys: this.env ? Object.keys(this.env) : [],
          hasGroqKey: Boolean(this.env?.GROQ_API_KEY)
        });
        return new Response(JSON.stringify({
          error: 'Service not properly configured: Missing required environment variables'
        }), {
          status: 503, // Service Unavailable
          headers: { 'Content-Type': 'application/json' }
        });
      }

      // Ensure request is using POST method
      if (request.method !== 'POST') {
        return new Response('Method not allowed', { status: 405 });
      }

      // Parse request body and validate required fields
      const { input } = await request.json() as { input: string };

      if (!input) {
        return new Response('Input is required', { status: 400 });
      }

      // Process the input through our agent
      const response = await this.agent.processInput(input);

      // Return successful response
      return new Response(JSON.stringify({ response }), {
        headers: { 'Content-Type': 'application/json' }
      });

    } catch (error) {
      console.error('Error:', error);

      // Provide detailed error information
      const errorResponse = {
        error: error instanceof Error ? error.message : 'Internal server error',
        type: error instanceof Error ? error.constructor.name : 'Unknown'
      };

      // Return error response
      return new Response(JSON.stringify(errorResponse), {
        status: 500,
        headers: { 'Content-Type': 'application/json' }
      });
    }
  }
}